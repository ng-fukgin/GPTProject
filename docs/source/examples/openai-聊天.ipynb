{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 聊天\n",
    "\n",
    "给定描述对话的消息列表，模型将返回响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\GPTProject\\docs\\source\\examples\\openai-图片.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/GPTProject/docs/source/examples/openai-%E5%9B%BE%E7%89%87.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0\n",
    "## 让后面的代码不执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建聊天\n",
    " \n",
    "``https://api.openai.com/v1/chat/completions``\n",
    "\n",
    "为给定的聊天对话创建模型响应。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": \"Hi there! How can I assist you today?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 参数名称 | 类型 | 是否必须 | 默认值 | 描述 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| model | string | Required |-| 要使用的模型的 ID。有关哪些模型与 Chat API 兼容的详细信息，请参阅模型端点兼容性表。|\n",
    "| messages | array | Required |-| 描述到目前为止的对话的消息列表。|\n",
    "| role | string | Required |-| 此消息的作者的角色。是 system、user 或 assistant 之一。|\n",
    "| content | string | Required |-| 消息内容。|\n",
    "| name | string | Optional |-| 此消息的作者的名称。可能包含 a-z、A-Z、0-9 和下划线，最大长度为 64 个字符。|\n",
    "| temperature | number | Optional | 1 | 要使用的采样温度，介于 0 和 2 之间。较高的值（如 0.8）会使输出更随机，而较低的值（如 0.2）会使其更集中和确定性。我们通常建议更改此项或 top_p，但不要同时更改两者。|\n",
    "| top_p | number | Optional | 1 | 一种称为核采样的温度采样替代方案，其中模型考虑具有 top_p 概率质量的令牌结果。因此，0.1 表示仅考虑组成前 10% 概率质量的令牌。我们通常建议更改此项或 temperature，但不要同时更改两者。|\n",
    "| n | integer | Optional | 1 | 每个输入消息生成多少个聊天句子可供选择。|\n",
    "| stream | boolean | Optional | false | 如果设置，则将发送部分消息增量，就像 ChatGPT 中一样。令牌将在可用时作为仅数据服务器发送事件发送，流由 data: [DONE] 消息终止。请参阅 OpenAI Cookbook 中的示例代码。|\n",
    "| stop | string or array | Optional |-| 最多 4 个序列，其中 API 将停止生成进一步令牌。|\n",
    "| max_tokens | integer | Optional |-| 聊天完成中生成的最大令牌数。输入令牌和生成令牌的总长度受模型上下文长度的限制。|\n",
    "| presence_penalty | number | Optional | 0 | 介于 -2.0 和 2.0 之间的数字。正值根据新令牌是否出现在迄今为止的文本中惩罚新令牌，增加模型谈论新主题的可能性。有关频率和存在惩罚的更多信息。|\n",
    "| frequency_penalty | number | Optional | 0 | 介于 -2.0 和 2.0 之间的数字。正值根据新令牌在迄今为止的文本中的现有频率惩罚新令牌，降低模型重复相同行的可能性。有关频率和存在惩罚的更多信息。|\n",
    "| logit_bias | map | Optional |-| 修改完成中指定令牌出现的可能性。接受一个 json 对象，该对象将令牌（由分词器中的令牌 ID 指定）映射到 -100 到 100 的相关偏差值。从数学上讲，偏差被添加到模型生成的 logits 中，然后进行采样。具体效果将因模型而异，但 -1 和 1 之间的值应减少或增加选择的可能性；像 -100 或 100 这样的值应导致相关令牌被禁止或独占选择。|\n",
    "| user | string | Optional |-| 表示您的最终用户的唯一标识符，可帮助 OpenAI 监控和检测滥用。|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连续对话\n",
    "    \n",
    "    openai支持连续对话，即在一个对话中，模型可以根据上下文来生成响应。这个功能可以通过设置{\"role\": \"xxx\", \"content\": \"xxx!\"}来实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好的，下面是一篇以“小友”为代替说述猫的作文：\\n\\n我们家住着一只小友，它被我们叫做“夜枭”， 因为它总是夜里出没，寻找各种小东西来玩耍。\\n\\n夜枭的身体非常柔软，身形婀娜优雅，行动也十分轻盈迅速。常常在观察周围的环境后随意向前一跃，轻轻松松地跳到了高处。\\n\\n夜枭的耳朵一直竖起来，似乎在聆听周围的声音，时时刻刻保持警觉。我们家里的其他小动物也很喜欢和夜枭玩耍，夜枭也总是能够顾及到这些小伙伴们的感受，让他们玩的又开心又安全。\\n\\n夜枭的毛发非常美观整洁，摸上去也很柔软。它的眼睛有着绿色的光芒，看上去非常明亮，仿佛可以照亮它的周围。\\n\\n虽然有时候夜枭有点淘气，可我们家里的每一个人都很喜欢它。每天早晨，我们都能听到夜枭轻轻的叫声，好像在告诉我们新的一天已经开始了。\\n\\n夜枭给我们带来了许多快乐和惊喜，我们永远都不会忘记这样一个温柔、独立又可爱的小友。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\n",
    "  \"content\": \"Hi there! How can I assist you today?\",\n",
    "  \"role\": \"assistant\"\n",
    "},\n",
    "    {\"role\": \"user\", \"content\": \"说中文!\"},\n",
    "    {\"role\": \"assistant\", \"content\": '好的！有什么我可以帮您的呢？'},\n",
    "    {\"role\": \"user\", \"content\": \"帮我写一篇作文，字数在300字左右，主题是“猫”,但是在文章中不能出现“猫”这个字\"},\n",
    "  ]\n",
    "  \n",
    ")\n",
    "\n",
    "completion.choices[0].message['content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
